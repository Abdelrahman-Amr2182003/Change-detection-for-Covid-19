{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\conda\\envs\\iris\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From E:\\conda\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import pygame\n",
    "import os\n",
    "from keras.models import load_model\n",
    "try:\n",
    "    os.mkdir('output_images')\n",
    "except:\n",
    "    pass\n",
    "sift=cv2.xfeatures2d.SIFT_create()\n",
    "def allign(img_querry,img_train):\n",
    "    kp_query,desc_query=sift.detectAndCompute(img_querry,None)\n",
    "    kp_train,desc_train=sift.detectAndCompute(img_train,None)\n",
    "    index_params = dict(algorithm=0, trees=5)# the indexes that we will be searching in\n",
    "    search_params = dict()# the search parameters of our search\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(desc_query, desc_train, k=2)# try to find the matches between the decriptors in he first img  and the second one\n",
    "    good=[]\n",
    "    for m,n in matches:\n",
    "        if m.distance <0.75*n.distance:\n",
    "            good.append(m)\n",
    "    matches=cv2.drawMatches(img_querry,kp_query,img_train,kp_train,good,None)\n",
    "    #cv2.imshow(\"matches\",matches)\n",
    "    q_p=np.float32([kp_query[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    t_p=np.float32([kp_train[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    try:\n",
    "        matrix,mask=cv2.findHomography(q_p,t_p,cv2.RANSAC)\n",
    "        alligned=cv2.warpPerspective(img_querry,matrix,(img_train.shape[1],img_train.shape[0]))\n",
    "    except:\n",
    "        try:\n",
    "            matrix=cv2.getPerspectiveTransform(q_p,t_p)\n",
    "            alligned=cv2.warpPerspective(img_querry,matrix,(img_train.shape[1],img_train.shape[0]))\n",
    "\n",
    "        except:\n",
    "            matrix=cv2.getAffineTransform(q_p,t_p)\n",
    "            alligned=cv2.warpAffine(img_querry,matrix,(img_train.shape[1],img_train.shape[0]))\n",
    "\n",
    "            \n",
    "    return alligned\n",
    "\n",
    "def compare(img_1,img_2):\n",
    "    delta=cv2.subtract(img_1,img_2)# 1-2\n",
    "    delta_2=cv2.subtract(img_2,img_1)#2-1\n",
    "    gray=cv2.cvtColor(delta,cv2.COLOR_BGR2GRAY)\n",
    "    gray_2=cv2.cvtColor(delta_2,cv2.COLOR_BGR2GRAY)\n",
    "    blured=cv2.GaussianBlur(gray,(5,5),0)# src,kernel_size,standard deviation\n",
    "    blured_2=cv2.GaussianBlur(gray_2,(5,5),0)\n",
    "    _,mask=cv2.threshold(blured,80,255,cv2.THRESH_BINARY)\n",
    "    _,mask_2=cv2.threshold(blured_2,80,255,cv2.THRESH_BINARY)\n",
    "    erosion = cv2.erode(mask,None,iterations = 1)\n",
    "    erosion_2=cv2.erode(mask_2,None,iterations=1)\n",
    "    cnts=cv2.findContours(erosion,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)[-2]# cnts approximaion method\n",
    "    cnts_2=cv2.findContours(erosion_2,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    \n",
    "    for cnt in cnts:\n",
    "        area=cv2.contourArea(cnt)\n",
    "        if area>200:\n",
    "            cv2.drawContours(img_2,cnt,-1,(255,0,0),2)# -1 stands for cnt index\n",
    "    for cnt in cnts_2:\n",
    "        area=cv2.contourArea(cnt)\n",
    "        if area>200:\n",
    "            cv2.drawContours(img_2,cnt,-1,(0,0,255),2)# -1 stands for cnt index    \n",
    "    return mask,mask_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imgs_dir=glob.glob('images_to_be_detected//*')\n",
    "model=load_model('classfier_binary_3.h5')\n",
    "states=['Normal','Infected']\n",
    "for i in range(len(imgs_dir)-1):\n",
    "    img=cv2.imread(imgs_dir[i])\n",
    "    img_1=cv2.imread(imgs_dir[i+1])\n",
    "    img_new=allign(img_1,img)\n",
    "    diff,diff_2=compare(img,img_new)\n",
    "    #cv2.imshow('diff_2',diff_2)\n",
    "    #cv2.imshow('diff',diff)\n",
    "    img_o_k=np.array((cv2.resize(img,(256,256)))/(255.0)).reshape(-1,256,256,3)\n",
    "    img_n_k=np.array((cv2.resize(img_new,(256,256)))/(255.0)).reshape(-1,256,256,3)\n",
    "    \n",
    "    old_state=model.predict(img_o_k)\n",
    "    new_state=model.predict(img_n_k)\n",
    "    if old_state>=0.5:\n",
    "        old_state=1\n",
    "    elif old_state<0.5:\n",
    "        old_state=0\n",
    "        \n",
    "    if new_state>=0.5:\n",
    "        new_state=1\n",
    "    elif new_state<0.5:\n",
    "        new_state=0\n",
    "    \n",
    "    #cv2.imshow('old',img)\n",
    "    #cv2.imshow('img_1',img_1)\n",
    "    #cv2.imshow('new',img_new)\n",
    "    conc=np.concatenate((img,img_new),axis=1)\n",
    "    cv2.line(conc,(conc.shape[1]//2,0),(conc.shape[1]//2,conc.shape[0]),(0,255,0),2)\n",
    "    cv2.putText(conc,'Old image',(20,30),cv2.FONT_HERSHEY_COMPLEX,0.9,(255,255,0),2)\n",
    "    cv2.putText(conc,'New image',(conc.shape[1]-190,30),cv2.FONT_HERSHEY_COMPLEX,0.9,(255,255,0),2)\n",
    "    \n",
    "    cv2.putText(conc,states[old_state],(20,60),cv2.FONT_HERSHEY_COMPLEX,0.9,(255,255,0),2)\n",
    "    cv2.putText(conc,states[new_state],(conc.shape[1]-190,60),cv2.FONT_HERSHEY_COMPLEX,0.9,(255,255,0),2)\n",
    "    cv2.imwrite(f'output_images//{i}.jpg',conc)\n",
    "    #cv2.imshow('conc',conc)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class GUI:\n",
    "    def __init__(self):\n",
    "        self.width=1200\n",
    "        self.height=800\n",
    "        self.white=(255,255,255)\n",
    "        self.fps=60\n",
    "        self.to_show_index=0\n",
    "        self.win=pygame.display.set_mode((self.width,self.height))\n",
    "        self.run=True\n",
    "        pygame.display.set_caption('Change detection from CT_scan for COVID-19')\n",
    "        self.directory=glob.glob(r'output_images//*')\n",
    "        self.clock=pygame.time.Clock()\n",
    "        self.imgs=[]\n",
    "        for i in self.directory:\n",
    "            self.imgs.append(pygame.transform.scale(pygame.image.load(i),(self.width,self.height)))\n",
    "        \n",
    "    def draw(self):\n",
    "        self.win.fill(self.white)\n",
    "        self.win.blit(self.imgs[self.to_show_index],(0,0))\n",
    "        pygame.display.update()\n",
    "    def main(self):\n",
    "        while self.run:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type ==pygame.QUIT:\n",
    "                    self.run=False\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                if event.type==pygame.KEYDOWN:\n",
    "                    if event.key==pygame.K_RIGHT:\n",
    "                        if self.to_show_index==len(self.directory)-1:\n",
    "                            self.to_show_index=0\n",
    "                        else:\n",
    "                            self.to_show_index+=1\n",
    "                    if event.key ==pygame.K_LEFT:\n",
    "                        if self.to_show_index==0:\n",
    "                            self.to_show_index=len(self.directory)-1\n",
    "                        else:\n",
    "                            self.to_show_index-=1\n",
    "            self.draw()\n",
    "\n",
    "G=GUI()\n",
    "G.main()        \n",
    "            \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
